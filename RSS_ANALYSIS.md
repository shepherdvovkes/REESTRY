# Анализ обработки RSS-источников в системе

## Текущее состояние

### 1. Обнаружение RSS-источников краулером

**Краулер (`UkrDeepCrawler/crawler.py`):**

❌ **RSS-фиды НЕ распознаются специально**

Анализ кода показывает:

1. **LLM-промпт для анализа страниц** (строки 193-217):
   - Ищет: `data_portal, registry, api_docs, search_page`
   - **RSS/Atom feeds НЕ упоминаются**

2. **LLM-промпт для извлечения ссылок** (строки 256-291):
   - Ищет ссылки на: реестры, API endpoints, файлы данных, документацию
   - **RSS-фиды НЕ упоминаются в списке искомых типов**

3. **Что произойдет, если краулер найдет RSS-ссылку:**
   - Ссылка может быть найдена как обычная ссылка
   - LLM может классифицировать её как `data_file` (если URL содержит `.xml` или `.rss`)
   - Или как обычная веб-страница
   - **НЕ будет распознана как специальный тип источника для обновлений**

### 2. Обработка RSS-источников системой загрузки

**Система загрузки (`data_management/download.py`):**

❌ **RSS-фиды НЕ поддерживаются специально**

Текущие адаптеры:
- `APISourceAdapter` - для REST API
- `FileSourceAdapter` - для CSV, JSON, XML файлов
- `WebSourceAdapter` - для веб-страниц с пагинацией

**Что произойдет с RSS-фидом:**

1. Если URL заканчивается на `.rss`, `.xml` или содержит `/feed`:
   - Может быть обработан как `FileSourceAdapter` (XML файл)
   - Или как `WebSourceAdapter` (веб-страница)

2. **Проблемы:**
   - ❌ Не будет распознана структура RSS (items, pubDate, link)
   - ❌ Не будет использована логика инкрементального обновления по датам публикации
   - ❌ Не будет отслеживаться последняя обработанная запись
   - ❌ RSS-специфичные поля (title, description, guid) не будут извлечены

## Рекомендации

### 1. Добавить распознавание RSS в краулер

**Обновить промпт LLM** для поиска RSS-источников:

```python
# В методе llm_extract_relevant_links добавить:
"""
Найди ссылки на:
...
7. RSS/Atom feeds (/feed, /rss, .rss, .xml с RSS-структурой)
8. Источники обновлений данных (новости, изменения, обновления)
"""
```

**Добавить эвристики для обнаружения RSS:**
- Поиск ссылок с текстом "RSS", "Feed", "Подписка"
- Поиск ссылок типа `/feed`, `/rss`, `/atom`
- Проверка заголовков страницы на наличие RSS-ссылок (`<link rel="alternate" type="application/rss+xml">`)

### 2. Создать RSSFeedAdapter

**Новый адаптер для RSS-фидов:**

```python
class RSSFeedAdapter(DataSourceAdapter):
    """Адаптер для RSS/Atom feeds"""
    
    def __init__(self, url: str):
        super().__init__(url)
        self.feedparser = None  # Использовать библиотеку feedparser
    
    def estimate_total(self) -> int:
        """Оценка количества записей в фиде"""
        feed = self._parse_feed()
        return len(feed.entries) if feed else -1
    
    def download_incremental(self, offset: int, limit: int) -> List[Dict]:
        """Загрузка записей из RSS-фида"""
        feed = self._parse_feed()
        if not feed:
            return []
        
        # RSS-фиды обычно отсортированы по дате (новые первыми)
        entries = feed.entries[offset:offset + limit]
        
        records = []
        for entry in entries:
            record = {
                'id': entry.get('id') or entry.get('link'),
                'title': entry.get('title', ''),
                'description': entry.get('description', ''),
                'link': entry.get('link', ''),
                'published': entry.get('published', ''),
                'updated': entry.get('updated', ''),
                'author': entry.get('author', ''),
                'categories': entry.get('tags', []),
                'content': entry.get('content', [{}])[0].get('value', '') if entry.get('content') else ''
            }
            records.append(record)
        
        return records
    
    def _parse_feed(self):
        """Парсинг RSS-фида"""
        import feedparser
        return feedparser.parse(self.url)
```

### 3. Интеграция с системой обнаружения изменений

**RSS-фиды идеально подходят для инкрементального обновления:**

- ✅ Автоматическое отслеживание новых записей по дате публикации
- ✅ RSS-фиды обычно содержат только новые/обновленные записи
- ✅ Структурированный формат упрощает парсинг
- ✅ Метаданные (дата, автор, категории) уже включены

**Обновить ChangeDetector** для работы с RSS:
- Использовать `published` дату для определения новых записей
- Использовать `guid` или `link` для идентификации записей
- Сравнивать по дате публикации, а не по хешу содержимого

### 4. Обновить систему регистрации источников

**Добавить тип источника `rss`:**

```python
# В DataDownloadManager
self.adapters = {
    'api': APISourceAdapter,
    'file': FileSourceAdapter,
    'web': WebSourceAdapter,
    'rss': RSSFeedAdapter  # Новый адаптер
}
```

## Примеры RSS-источников в украинских госпорталах

Типичные места, где можно найти RSS-фиды:

1. **Порталы новостей и обновлений:**
   - `https://data.gov.ua/feed` - обновления на портале открытых данных
   - `https://minjust.gov.ua/rss` - новости министерства юстиции
   - `https://nazk.gov.ua/feed` - обновления НАЗК

2. **Реестры с RSS-подписками:**
   - Реестры часто предоставляют RSS для отслеживания изменений
   - Например: `/feed/changes`, `/rss/updates`

3. **Документация API:**
   - Некоторые API предоставляют RSS для отслеживания изменений в документации

## План реализации

### Этап 1: Обнаружение RSS (высокий приоритет)
1. Обновить промпты LLM в краулере
2. Добавить эвристики для поиска RSS-ссылок
3. Добавить тип источника `rss` в классификацию

### Этап 2: Парсинг RSS (высокий приоритет)
1. Установить библиотеку `feedparser`
2. Создать `RSSFeedAdapter`
3. Интегрировать в `DataDownloadManager`

### Этап 3: Инкрементальное обновление (средний приоритет)
1. Обновить `ChangeDetector` для работы с RSS
2. Использовать даты публикации для определения новых записей
3. Добавить поддержку в `PeriodicScheduler`

### Этап 4: Мониторинг (низкий приоритет)
1. Добавить метрики для RSS-источников
2. Отслеживание доступности фидов
3. Алерты при недоступности RSS

## Выводы

**Текущее состояние:**
- ❌ RSS-фиды НЕ распознаются специально
- ❌ RSS-фиды НЕ обрабатываются оптимально
- ⚠️ Могут быть найдены случайно, но обработаны неправильно

**После реализации:**
- ✅ RSS-фиды будут автоматически обнаруживаться
- ✅ Оптимальная обработка RSS-структуры
- ✅ Эффективное инкрементальное обновление
- ✅ Использование метаданных (даты, категории, авторы)

**Рекомендация:** Реализовать поддержку RSS как приоритетную задачу, так как RSS-фиды являются идеальным источником для автоматического отслеживания обновлений данных в государственных порталах.

